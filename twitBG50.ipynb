{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from keras.layers import Embedding, Dense, LSTM, Dense, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_labeled_tweets1.csv', nrows=1500000)\n",
    "#df = df['text'].str.split(' ')\n",
    "#to_remove = splits.apply(lambda x: len(x)).sort_values(ascending=False)[:10].index\n",
    "#df = df.drop(to_remove).reset_index(drop=True)\n",
    "#print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])\n",
    "splits = df['text'].str.split(' ')\n",
    "to_remove = splits.apply(lambda x: len(x)).sort_values(ascending=False)[:10].index\n",
    "df = df.drop(to_remove).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.dropna(subset=['text'])\n",
    "#df = df.drop_duplicates('text', inplace=True)\n",
    "#df = df.fillna(\"\")\n",
    "#df.dropna(axis=1, how='any')\n",
    "#df = df.dropna(thresh=1)\n",
    "#del df['$url$']\n",
    "#df1 = df.loc[df.notna().all()]\n",
    "#df = df.drop(df1)\n",
    "#splits= dftext'].str.split(' ')\n",
    "#to_remove = splits.apply(lambda x: len(x)).sort_values(ascending=False)[:10].index\n",
    "#df = df.drop(to_remove).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('<quoted_status>', '<quoted_status> ')\n",
    "df['text'] = df['text'].str.replace('<hashtag>', '<hashtag> ')\n",
    "df['text'] = df['text'].apply(lambda x: re.sub( '\\s+', ' ', x ).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_split = df['text'].str.split(' ', expand=True)\n",
    "words = df_clean_split.stack().unique()\n",
    "max_sequence = df_clean_split.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tockenizer = Tokenizer(words.shape[0]) \n",
    "tockenizer.fit_on_texts(df['text'])\n",
    "sequences = tockenizer.texts_to_sequences(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tockenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=max_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.twitter.27B.50d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train = data[:1100000,:]\n",
    "X_text_test = data[1100000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_data = df[['retweet_count', 'favorite_count', 'reply_count', 'hashtag_count', 'mention_count', 'url_count']].values\n",
    "\n",
    "X_number_train = number_data[:1100000,:]\n",
    "X_number_test = number_data[1100000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = df['BotOrNot'].values\n",
    "\n",
    "y_train = y_vals[:1100000].reshape(-1,1)\n",
    "y_test = y_vals[1100000:].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_sequence,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\STUDENT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "main_input = Input(shape=(max_sequence,), dtype='int32', name='main_input')\n",
    "embedded_sequences = embedding_layer(main_input)\n",
    "\n",
    "lstm_out = LSTM(32)(embedded_sequences)\n",
    "\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "auxiliary_input = Input(shape=(6,), name='aux_input')\n",
    "\n",
    "x = concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 318)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 318, 50)      21998100    main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           10624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 38)           0           lstm_1[0][0]                     \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          4992        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            65          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 22,022,070\n",
      "Trainable params: 23,970\n",
      "Non-trainable params: 21,998,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\STUDENT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1100000 samples, validate on 899357 samples\n",
      "Epoch 1/50\n",
      "1100000/1100000 [==============================] - 866s 788us/step - loss: 0.2747 - main_output_loss: 0.2262 - aux_output_loss: 0.2426 - main_output_acc: 0.9206 - aux_output_acc: 0.8996 - val_loss: 0.2205 - val_main_output_loss: 0.1801 - val_aux_output_loss: 0.2021 - val_main_output_acc: 0.9380 - val_aux_output_acc: 0.9207\n",
      "Epoch 2/50\n",
      "1100000/1100000 [==============================] - 868s 789us/step - loss: 0.2190 - main_output_loss: 0.1811 - aux_output_loss: 0.1898 - main_output_acc: 0.9404 - aux_output_acc: 0.9273 - val_loss: 0.2080 - val_main_output_loss: 0.1721 - val_aux_output_loss: 0.1795 - val_main_output_acc: 0.9429 - val_aux_output_acc: 0.9329\n",
      "Epoch 3/50\n",
      "1100000/1100000 [==============================] - 876s 796us/step - loss: 0.2039 - main_output_loss: 0.1691 - aux_output_loss: 0.1742 - main_output_acc: 0.9445 - aux_output_acc: 0.9360 - val_loss: 0.2326 - val_main_output_loss: 0.1986 - val_aux_output_loss: 0.1697 - val_main_output_acc: 0.9447 - val_aux_output_acc: 0.9389\n",
      "Epoch 4/50\n",
      "1100000/1100000 [==============================] - 872s 793us/step - loss: 0.2025 - main_output_loss: 0.1685 - aux_output_loss: 0.1703 - main_output_acc: 0.9466 - aux_output_acc: 0.9388 - val_loss: 0.2025 - val_main_output_loss: 0.1693 - val_aux_output_loss: 0.1663 - val_main_output_acc: 0.9433 - val_aux_output_acc: 0.9416\n",
      "Epoch 5/50\n",
      "1100000/1100000 [==============================] - 871s 792us/step - loss: 0.1852 - main_output_loss: 0.1529 - aux_output_loss: 0.1614 - main_output_acc: 0.9487 - aux_output_acc: 0.9413 - val_loss: 0.1832 - val_main_output_loss: 0.1510 - val_aux_output_loss: 0.1610 - val_main_output_acc: 0.9487 - val_aux_output_acc: 0.9405\n",
      "Epoch 6/50\n",
      "1100000/1100000 [==============================] - 864s 785us/step - loss: 0.1849 - main_output_loss: 0.1533 - aux_output_loss: 0.1579 - main_output_acc: 0.9497 - aux_output_acc: 0.9426 - val_loss: 0.2062 - val_main_output_loss: 0.1741 - val_aux_output_loss: 0.1602 - val_main_output_acc: 0.9483 - val_aux_output_acc: 0.9417\n",
      "Epoch 7/50\n",
      "1100000/1100000 [==============================] - 863s 784us/step - loss: 0.1846 - main_output_loss: 0.1536 - aux_output_loss: 0.1551 - main_output_acc: 0.9507 - aux_output_acc: 0.9437 - val_loss: 0.1843 - val_main_output_loss: 0.1530 - val_aux_output_loss: 0.1566 - val_main_output_acc: 0.9505 - val_aux_output_acc: 0.9438\n",
      "Epoch 8/50\n",
      "1100000/1100000 [==============================] - 862s 783us/step - loss: 0.1795 - main_output_loss: 0.1490 - aux_output_loss: 0.1527 - main_output_acc: 0.9515 - aux_output_acc: 0.9445 - val_loss: 0.1836 - val_main_output_loss: 0.1524 - val_aux_output_loss: 0.1559 - val_main_output_acc: 0.9506 - val_aux_output_acc: 0.9452\n",
      "Epoch 9/50\n",
      "1100000/1100000 [==============================] - 861s 782us/step - loss: 0.1699 - main_output_loss: 0.1398 - aux_output_loss: 0.1506 - main_output_acc: 0.9524 - aux_output_acc: 0.9453 - val_loss: 0.1728 - val_main_output_loss: 0.1422 - val_aux_output_loss: 0.1528 - val_main_output_acc: 0.9508 - val_aux_output_acc: 0.9439\n",
      "Epoch 10/50\n",
      "1100000/1100000 [==============================] - 864s 785us/step - loss: 0.1742 - main_output_loss: 0.1443 - aux_output_loss: 0.1495 - main_output_acc: 0.9525 - aux_output_acc: 0.9457 - val_loss: 0.1803 - val_main_output_loss: 0.1498 - val_aux_output_loss: 0.1527 - val_main_output_acc: 0.9516 - val_aux_output_acc: 0.9458\n",
      "Epoch 11/50\n",
      "1100000/1100000 [==============================] - 871s 792us/step - loss: 0.1727 - main_output_loss: 0.1432 - aux_output_loss: 0.1478 - main_output_acc: 0.9532 - aux_output_acc: 0.9463 - val_loss: 0.1732 - val_main_output_loss: 0.1429 - val_aux_output_loss: 0.1513 - val_main_output_acc: 0.9525 - val_aux_output_acc: 0.9456\n",
      "Epoch 12/50\n",
      "1100000/1100000 [==============================] - 861s 783us/step - loss: 0.1653 - main_output_loss: 0.1360 - aux_output_loss: 0.1466 - main_output_acc: 0.9537 - aux_output_acc: 0.9466 - val_loss: 0.1657 - val_main_output_loss: 0.1356 - val_aux_output_loss: 0.1505 - val_main_output_acc: 0.9528 - val_aux_output_acc: 0.9459\n",
      "Epoch 13/50\n",
      "1100000/1100000 [==============================] - 885s 805us/step - loss: 0.1642 - main_output_loss: 0.1350 - aux_output_loss: 0.1458 - main_output_acc: 0.9543 - aux_output_acc: 0.9469 - val_loss: 0.1674 - val_main_output_loss: 0.1374 - val_aux_output_loss: 0.1502 - val_main_output_acc: 0.9528 - val_aux_output_acc: 0.9454\n",
      "Epoch 14/50\n",
      "1100000/1100000 [==============================] - 892s 811us/step - loss: 0.1632 - main_output_loss: 0.1343 - aux_output_loss: 0.1448 - main_output_acc: 0.9545 - aux_output_acc: 0.9472 - val_loss: 0.1767 - val_main_output_loss: 0.1467 - val_aux_output_loss: 0.1500 - val_main_output_acc: 0.9529 - val_aux_output_acc: 0.9455\n",
      "Epoch 15/50\n",
      "1100000/1100000 [==============================] - 880s 800us/step - loss: 0.1631 - main_output_loss: 0.1344 - aux_output_loss: 0.1439 - main_output_acc: 0.9546 - aux_output_acc: 0.9476 - val_loss: 0.1668 - val_main_output_loss: 0.1370 - val_aux_output_loss: 0.1490 - val_main_output_acc: 0.9531 - val_aux_output_acc: 0.9470\n",
      "Epoch 16/50\n",
      "1100000/1100000 [==============================] - 881s 800us/step - loss: 0.1606 - main_output_loss: 0.1319 - aux_output_loss: 0.1431 - main_output_acc: 0.9549 - aux_output_acc: 0.9478 - val_loss: 0.1747 - val_main_output_loss: 0.1451 - val_aux_output_loss: 0.1480 - val_main_output_acc: 0.9530 - val_aux_output_acc: 0.9467\n",
      "Epoch 17/50\n",
      "1100000/1100000 [==============================] - 879s 799us/step - loss: 0.1616 - main_output_loss: 0.1330 - aux_output_loss: 0.1427 - main_output_acc: 0.9551 - aux_output_acc: 0.9480 - val_loss: 0.1748 - val_main_output_loss: 0.1450 - val_aux_output_loss: 0.1487 - val_main_output_acc: 0.9531 - val_aux_output_acc: 0.9473\n",
      "Epoch 18/50\n",
      "1100000/1100000 [==============================] - 875s 796us/step - loss: 0.1563 - main_output_loss: 0.1280 - aux_output_loss: 0.1415 - main_output_acc: 0.9557 - aux_output_acc: 0.9485 - val_loss: 0.1649 - val_main_output_loss: 0.1352 - val_aux_output_loss: 0.1485 - val_main_output_acc: 0.9533 - val_aux_output_acc: 0.9455\n",
      "Epoch 19/50\n",
      "1100000/1100000 [==============================] - 870s 791us/step - loss: 0.1594 - main_output_loss: 0.1311 - aux_output_loss: 0.1413 - main_output_acc: 0.9557 - aux_output_acc: 0.9486 - val_loss: 0.1755 - val_main_output_loss: 0.1459 - val_aux_output_loss: 0.1483 - val_main_output_acc: 0.9531 - val_aux_output_acc: 0.9465\n",
      "Epoch 20/50\n",
      "1100000/1100000 [==============================] - 877s 797us/step - loss: 0.1587 - main_output_loss: 0.1304 - aux_output_loss: 0.1415 - main_output_acc: 0.9558 - aux_output_acc: 0.9487 - val_loss: 0.1662 - val_main_output_loss: 0.1365 - val_aux_output_loss: 0.1486 - val_main_output_acc: 0.9530 - val_aux_output_acc: 0.9452\n",
      "Epoch 21/50\n",
      "1100000/1100000 [==============================] - 860s 782us/step - loss: 0.1539 - main_output_loss: 0.1259 - aux_output_loss: 0.1401 - main_output_acc: 0.9564 - aux_output_acc: 0.9491 - val_loss: 0.1670 - val_main_output_loss: 0.1375 - val_aux_output_loss: 0.1476 - val_main_output_acc: 0.9536 - val_aux_output_acc: 0.9464\n",
      "Epoch 22/50\n",
      "1100000/1100000 [==============================] - 864s 785us/step - loss: 0.1518 - main_output_loss: 0.1238 - aux_output_loss: 0.1399 - main_output_acc: 0.9564 - aux_output_acc: 0.9491 - val_loss: 0.1658 - val_main_output_loss: 0.1359 - val_aux_output_loss: 0.1493 - val_main_output_acc: 0.9527 - val_aux_output_acc: 0.9445\n",
      "Epoch 23/50\n",
      "1100000/1100000 [==============================] - 876s 796us/step - loss: 0.1532 - main_output_loss: 0.1253 - aux_output_loss: 0.1394 - main_output_acc: 0.9565 - aux_output_acc: 0.9492 - val_loss: 0.1781 - val_main_output_loss: 0.1487 - val_aux_output_loss: 0.1468 - val_main_output_acc: 0.9531 - val_aux_output_acc: 0.9478\n",
      "Epoch 24/50\n",
      "1100000/1100000 [==============================] - 889s 808us/step - loss: 0.1523 - main_output_loss: 0.1245 - aux_output_loss: 0.1390 - main_output_acc: 0.9566 - aux_output_acc: 0.9494 - val_loss: 0.1584 - val_main_output_loss: 0.1292 - val_aux_output_loss: 0.1460 - val_main_output_acc: 0.9542 - val_aux_output_acc: 0.9477\n",
      "Epoch 25/50\n",
      "1100000/1100000 [==============================] - 874s 795us/step - loss: 0.1504 - main_output_loss: 0.1227 - aux_output_loss: 0.1383 - main_output_acc: 0.9570 - aux_output_acc: 0.9496 - val_loss: 0.1608 - val_main_output_loss: 0.1316 - val_aux_output_loss: 0.1461 - val_main_output_acc: 0.9536 - val_aux_output_acc: 0.9470\n",
      "Epoch 26/50\n",
      "1100000/1100000 [==============================] - 872s 792us/step - loss: 0.1499 - main_output_loss: 0.1223 - aux_output_loss: 0.1380 - main_output_acc: 0.9571 - aux_output_acc: 0.9496 - val_loss: 0.1724 - val_main_output_loss: 0.1431 - val_aux_output_loss: 0.1463 - val_main_output_acc: 0.9540 - val_aux_output_acc: 0.9471\n",
      "Epoch 27/50\n",
      "1100000/1100000 [==============================] - 880s 800us/step - loss: 0.1491 - main_output_loss: 0.1215 - aux_output_loss: 0.1378 - main_output_acc: 0.9572 - aux_output_acc: 0.9498 - val_loss: 0.1644 - val_main_output_loss: 0.1349 - val_aux_output_loss: 0.1474 - val_main_output_acc: 0.9538 - val_aux_output_acc: 0.9459\n",
      "Epoch 28/50\n",
      "1100000/1100000 [==============================] - 877s 797us/step - loss: 0.1479 - main_output_loss: 0.1204 - aux_output_loss: 0.1374 - main_output_acc: 0.9574 - aux_output_acc: 0.9499 - val_loss: 0.1640 - val_main_output_loss: 0.1347 - val_aux_output_loss: 0.1462 - val_main_output_acc: 0.9542 - val_aux_output_acc: 0.9470\n",
      "Epoch 29/50\n",
      "1100000/1100000 [==============================] - 866s 787us/step - loss: 0.1473 - main_output_loss: 0.1199 - aux_output_loss: 0.1370 - main_output_acc: 0.9577 - aux_output_acc: 0.9501 - val_loss: 0.1610 - val_main_output_loss: 0.1318 - val_aux_output_loss: 0.1460 - val_main_output_acc: 0.9539 - val_aux_output_acc: 0.9481\n",
      "Epoch 30/50\n",
      "1100000/1100000 [==============================] - 867s 788us/step - loss: 0.1459 - main_output_loss: 0.1186 - aux_output_loss: 0.1367 - main_output_acc: 0.9577 - aux_output_acc: 0.9501 - val_loss: 0.1598 - val_main_output_loss: 0.1306 - val_aux_output_loss: 0.1460 - val_main_output_acc: 0.9544 - val_aux_output_acc: 0.9480\n",
      "Epoch 31/50\n",
      "1100000/1100000 [==============================] - 871s 792us/step - loss: 0.1445 - main_output_loss: 0.1172 - aux_output_loss: 0.1365 - main_output_acc: 0.9580 - aux_output_acc: 0.9503 - val_loss: 0.1582 - val_main_output_loss: 0.1291 - val_aux_output_loss: 0.1452 - val_main_output_acc: 0.9544 - val_aux_output_acc: 0.9473\n",
      "Epoch 32/50\n",
      "1100000/1100000 [==============================] - 887s 806us/step - loss: 0.1485 - main_output_loss: 0.1213 - aux_output_loss: 0.1362 - main_output_acc: 0.9579 - aux_output_acc: 0.9502 - val_loss: 0.1615 - val_main_output_loss: 0.1325 - val_aux_output_loss: 0.1448 - val_main_output_acc: 0.9547 - val_aux_output_acc: 0.9478\n",
      "Epoch 33/50\n",
      "1100000/1100000 [==============================] - 895s 814us/step - loss: 0.1529 - main_output_loss: 0.1246 - aux_output_loss: 0.1412 - main_output_acc: 0.9570 - aux_output_acc: 0.9497 - val_loss: 0.1606 - val_main_output_loss: 0.1316 - val_aux_output_loss: 0.1451 - val_main_output_acc: 0.9545 - val_aux_output_acc: 0.9475\n",
      "Epoch 34/50\n",
      "1100000/1100000 [==============================] - 894s 813us/step - loss: 0.1445 - main_output_loss: 0.1173 - aux_output_loss: 0.1360 - main_output_acc: 0.9581 - aux_output_acc: 0.9505 - val_loss: 0.1616 - val_main_output_loss: 0.1326 - val_aux_output_loss: 0.1450 - val_main_output_acc: 0.9544 - val_aux_output_acc: 0.9473\n",
      "Epoch 35/50\n",
      "1100000/1100000 [==============================] - 879s 799us/step - loss: 0.1452 - main_output_loss: 0.1180 - aux_output_loss: 0.1357 - main_output_acc: 0.9583 - aux_output_acc: 0.9505 - val_loss: 0.1588 - val_main_output_loss: 0.1298 - val_aux_output_loss: 0.1449 - val_main_output_acc: 0.9546 - val_aux_output_acc: 0.9475\n",
      "Epoch 36/50\n",
      "1100000/1100000 [==============================] - 872s 792us/step - loss: 0.1435 - main_output_loss: 0.1164 - aux_output_loss: 0.1357 - main_output_acc: 0.9584 - aux_output_acc: 0.9504 - val_loss: 0.1601 - val_main_output_loss: 0.1310 - val_aux_output_loss: 0.1451 - val_main_output_acc: 0.9546 - val_aux_output_acc: 0.9476\n",
      "Epoch 37/50\n",
      "1100000/1100000 [==============================] - 868s 789us/step - loss: 0.1459 - main_output_loss: 0.1187 - aux_output_loss: 0.1357 - main_output_acc: 0.9585 - aux_output_acc: 0.9503 - val_loss: 0.1599 - val_main_output_loss: 0.1309 - val_aux_output_loss: 0.1451 - val_main_output_acc: 0.9546 - val_aux_output_acc: 0.9476\n",
      "Epoch 38/50\n",
      "1100000/1100000 [==============================] - 864s 785us/step - loss: 0.1456 - main_output_loss: 0.1184 - aux_output_loss: 0.1356 - main_output_acc: 0.9586 - aux_output_acc: 0.9505 - val_loss: 0.1618 - val_main_output_loss: 0.1328 - val_aux_output_loss: 0.1449 - val_main_output_acc: 0.9549 - val_aux_output_acc: 0.9475\n",
      "Epoch 39/50\n",
      "1100000/1100000 [==============================] - 862s 784us/step - loss: 0.1440 - main_output_loss: 0.1169 - aux_output_loss: 0.1356 - main_output_acc: 0.9587 - aux_output_acc: 0.9506 - val_loss: 0.1599 - val_main_output_loss: 0.1310 - val_aux_output_loss: 0.1448 - val_main_output_acc: 0.9547 - val_aux_output_acc: 0.9476\n",
      "Epoch 40/50\n",
      "1100000/1100000 [==============================] - 863s 784us/step - loss: 0.1437 - main_output_loss: 0.1166 - aux_output_loss: 0.1354 - main_output_acc: 0.9588 - aux_output_acc: 0.9505 - val_loss: 0.1728 - val_main_output_loss: 0.1437 - val_aux_output_loss: 0.1454 - val_main_output_acc: 0.9544 - val_aux_output_acc: 0.9472\n",
      "Epoch 41/50\n",
      "1100000/1100000 [==============================] - 863s 784us/step - loss: 0.1437 - main_output_loss: 0.1167 - aux_output_loss: 0.1354 - main_output_acc: 0.9590 - aux_output_acc: 0.9506 - val_loss: 0.1734 - val_main_output_loss: 0.1444 - val_aux_output_loss: 0.1450 - val_main_output_acc: 0.9543 - val_aux_output_acc: 0.9475\n",
      "Epoch 42/50\n",
      "1100000/1100000 [==============================] - 862s 784us/step - loss: 0.1433 - main_output_loss: 0.1162 - aux_output_loss: 0.1355 - main_output_acc: 0.9589 - aux_output_acc: 0.9505 - val_loss: 0.1589 - val_main_output_loss: 0.1300 - val_aux_output_loss: 0.1445 - val_main_output_acc: 0.9550 - val_aux_output_acc: 0.9477\n",
      "Epoch 43/50\n",
      "1100000/1100000 [==============================] - 866s 787us/step - loss: 0.1419 - main_output_loss: 0.1149 - aux_output_loss: 0.1350 - main_output_acc: 0.9591 - aux_output_acc: 0.9507 - val_loss: 0.1705 - val_main_output_loss: 0.1415 - val_aux_output_loss: 0.1447 - val_main_output_acc: 0.9545 - val_aux_output_acc: 0.9476\n",
      "Epoch 44/50\n",
      "1100000/1100000 [==============================] - 866s 787us/step - loss: 0.1444 - main_output_loss: 0.1173 - aux_output_loss: 0.1352 - main_output_acc: 0.9591 - aux_output_acc: 0.9507 - val_loss: 0.1633 - val_main_output_loss: 0.1341 - val_aux_output_loss: 0.1461 - val_main_output_acc: 0.9542 - val_aux_output_acc: 0.9464\n",
      "Epoch 45/50\n",
      "1100000/1100000 [==============================] - 870s 791us/step - loss: 0.1446 - main_output_loss: 0.1175 - aux_output_loss: 0.1353 - main_output_acc: 0.9590 - aux_output_acc: 0.9505 - val_loss: 0.1626 - val_main_output_loss: 0.1334 - val_aux_output_loss: 0.1464 - val_main_output_acc: 0.9543 - val_aux_output_acc: 0.9466\n",
      "Epoch 46/50\n",
      "1100000/1100000 [==============================] - 870s 791us/step - loss: 0.1422 - main_output_loss: 0.1151 - aux_output_loss: 0.1353 - main_output_acc: 0.9591 - aux_output_acc: 0.9505 - val_loss: 0.1601 - val_main_output_loss: 0.1312 - val_aux_output_loss: 0.1447 - val_main_output_acc: 0.9550 - val_aux_output_acc: 0.9482\n",
      "Epoch 47/50\n",
      "1100000/1100000 [==============================] - 864s 785us/step - loss: 0.1444 - main_output_loss: 0.1173 - aux_output_loss: 0.1352 - main_output_acc: 0.9591 - aux_output_acc: 0.9507 - val_loss: 0.1628 - val_main_output_loss: 0.1339 - val_aux_output_loss: 0.1444 - val_main_output_acc: 0.9548 - val_aux_output_acc: 0.9479\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100000/1100000 [==============================] - 862s 784us/step - loss: 0.1473 - main_output_loss: 0.1203 - aux_output_loss: 0.1349 - main_output_acc: 0.9592 - aux_output_acc: 0.9508 - val_loss: 0.1623 - val_main_output_loss: 0.1334 - val_aux_output_loss: 0.1445 - val_main_output_acc: 0.9548 - val_aux_output_acc: 0.9478\n",
      "Epoch 49/50\n",
      "1100000/1100000 [==============================] - 856s 778us/step - loss: 0.1446 - main_output_loss: 0.1176 - aux_output_loss: 0.1350 - main_output_acc: 0.9593 - aux_output_acc: 0.9508 - val_loss: 0.1644 - val_main_output_loss: 0.1355 - val_aux_output_loss: 0.1448 - val_main_output_acc: 0.9542 - val_aux_output_acc: 0.9470\n",
      "Epoch 50/50\n",
      "1100000/1100000 [==============================] - 856s 778us/step - loss: 0.1422 - main_output_loss: 0.1154 - aux_output_loss: 0.1345 - main_output_acc: 0.9594 - aux_output_acc: 0.9509 - val_loss: 0.1706 - val_main_output_loss: 0.1418 - val_aux_output_loss: 0.1442 - val_main_output_acc: 0.9549 - val_aux_output_acc: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7f650e208>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'main_input': X_text_train, 'aux_input': X_number_train},\n",
    "          {'main_output': y_train, 'aux_output': y_train},\n",
    "          validation_data=[{'main_input': X_text_test, 'aux_input': X_number_test}, {'main_output': y_test, 'aux_output': y_test}],\n",
    "          epochs=50, \n",
    "          batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[     0,      0,      0, ...,   7505,    458,    955],\n       [     0,      0,      0, ...,     28,      3,   1247],\n       [     0,      0,      0, ...,    337,    136,    141],\n       ...,\n ...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5c9d3ca66c7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredicted_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[     0,      0,      0, ...,   7505,    458,    955],\n       [     0,      0,      0, ...,     28,      3,   1247],\n       [     0,      0,      0, ...,    337,    136,    141],\n       ...,\n ..."
     ]
    }
   ],
   "source": [
    "np.array(X_text_train)\n",
    "predicted_classes = model.predict(X_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted_classes = model.predict(X_text_test, batch_size=32, verbose=1 )\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y-test, predicted_classes, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
